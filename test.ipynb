{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import pickle\n",
    "from src.MIL.ABMIL import *\n",
    "import sklearn.metrics as metrics\n",
    "import sys \n",
    "sys.path.append('src/MIL')\n",
    "from src.MIL.ABMIL import *\n",
    "from src.MIL.VarMIL import *\n",
    "from src.MIL.CLAM import *\n",
    "from src.MIL.TransMIL import *\n",
    "import src.MIL.DSMIL as dsmil\n",
    "from src.MIL.ACMIL import *\n",
    "from src.MIL.AttriMIL import *\n",
    "from src.utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import timm\n",
    "# from timm.data import resolve_data_config\n",
    "# from timm.data.transforms_factory import create_transform\n",
    "# from huggingface_hub import login\n",
    "\n",
    "# login(token = \"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\")  # login with your User Access Token, found at https://huggingface.co/settings/tokens\n",
    "\n",
    "# # pretrained=True needed to load UNI weights (and download weights for the first time)\n",
    "# # init_values need to be passed in to successfully load LayerScale parameters (e.g. - block.0.ls1.gamma)\n",
    "# model = timm.create_model(\"hf-hub:MahmoodLab/UNI\", pretrained=True, init_values=1e-5, dynamic_img_size=True)\n",
    "# transform = create_transform(**resolve_data_config(model.pretrained_cfg, model=model))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# image = Image.open(\"UNI/.github/uni.jpg\")\n",
    "# image = transform(image).unsqueeze(dim=0) # Image (torch.Tensor) with shape [1, 3, 224, 224] following image resizing and normalization (ImageNet parameters)\n",
    "# with torch.inference_mode():\n",
    "#     feature_emb = model(image) # Extracted features (torch.Tensor) with shape [1,1024]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ABMIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"data/train_dict.pkl\"\n",
    "with open(file_path, 'rb') as f:\n",
    "    train_dict = pickle.load(f)\n",
    "\n",
    "file_path = \"data/test_dict.pkl\"\n",
    "with open(file_path, 'rb') as f:\n",
    "    test_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_dict['embeddings'][:,1:,:]\n",
    "y_train = train_dict['labels']\n",
    "X_test = test_dict['embeddings'][:,1:,:]\n",
    "y_test = test_dict['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), \n",
    "                               torch.tensor(y_train, dtype=torch.int))\n",
    "test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), \n",
    "                              torch.tensor(y_test, dtype=torch.int))\n",
    "\n",
    "# Define DataLoaders\n",
    "batch_size = 1  # Adjust batch size as needed\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BASELINE : Embedding +Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Emb_mean()\n",
    "#TRAIN THE MODEL\n",
    "for epoch in range(1, 20):\n",
    "    train(train_loader,epoch, model, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(test_loader,y_test,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BASELINE : Embedding +max "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Emb_max()\n",
    "#TRAIN THE MODEL\n",
    "for epoch in range(1, 20):\n",
    "    train(train_loader,epoch, model, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(test_loader,y_test,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ATTENTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Attention(hidden_size=512, dropout=0.5)\n",
    "#TRAIN THE MODEL\n",
    "for epoch in range(1, 20):\n",
    "    train(train_loader,epoch, model, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(test_loader,y_test,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_ABMIL = {'hidden_size': [128,512], 'dropout': [0,0.1,0.2,0.3,0.5], 'lr': [0.001, 0.01], 'weight_decay': [0.0005, 0.005]}\n",
    "\n",
    "hyperparam_tuning(train_loader, test_loader, y_test, hyp_ABMIL,Attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gated Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GatedAttention(hidden_size=512, dropout=0.1)\n",
    "#TRAIN THE MODEL\n",
    "for epoch in range(1, 20):\n",
    "    train(train_loader,epoch, model, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(test_loader,y_test,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_ABMIL = {'hidden_size': [128,512], 'dropout': [0,0.1,0.2,0.3,0.5], 'lr': [0.001, 0.01], 'weight_decay': [0.0005, 0.005]}\n",
    "\n",
    "hyperparam_tuning(train_loader, test_loader, y_test, hyp_ABMIL,GatedAttention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VARMIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VarMIL(embed_size= 1024, hidden_size=500,separate_attn=False, dropout=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 20):\n",
    "    train(train_loader,epoch, model, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(test_loader,y_test,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_VarMIL = {'hidden_size': [128,512],'gated':[True,False], 'separate_attn':[False,True] , 'dropout': [0,0.1,0.2,0.3,0.5], 'n_var_pool':[50,100,150,200],'act_func':['sqrt', 'log', 'sigmoid'], 'lr': [0.001, 0.01], 'weight_decay': [0.0005, 0.005]}\n",
    "\n",
    "hyperparam_tuning(train_loader, test_loader, y_test, hyp_VarMIL,VarMIL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.5606, Train error: 0.1385\n",
      "Epoch: 2, Loss: 0.1565, Train error: 0.0308\n",
      "Epoch: 3, Loss: 0.2959, Train error: 0.0308\n",
      "Epoch: 4, Loss: 0.3383, Train error: 0.0308\n",
      "Epoch: 5, Loss: 0.2589, Train error: 0.0385\n",
      "Epoch: 6, Loss: 0.1944, Train error: 0.0462\n",
      "Epoch: 7, Loss: 0.3807, Train error: 0.0308\n",
      "Epoch: 8, Loss: 0.1324, Train error: 0.0308\n",
      "Epoch: 9, Loss: 0.0739, Train error: 0.0154\n",
      "Epoch: 10, Loss: 0.4016, Train error: 0.0385\n",
      "Epoch: 11, Loss: 0.4406, Train error: 0.0462\n",
      "Epoch: 12, Loss: 0.2262, Train error: 0.0000\n",
      "Epoch: 13, Loss: 0.2700, Train error: 0.0308\n",
      "Epoch: 14, Loss: 0.1352, Train error: 0.0231\n",
      "Epoch: 15, Loss: 0.1845, Train error: 0.0154\n",
      "Epoch: 16, Loss: 0.4021, Train error: 0.0308\n",
      "Epoch: 17, Loss: 0.1487, Train error: 0.0462\n",
      "Epoch: 18, Loss: 0.6700, Train error: 0.0308\n",
      "Epoch: 19, Loss: 0.1234, Train error: 0.0308\n"
     ]
    }
   ],
   "source": [
    "model = CLAM_SB()\n",
    "#TRAIN THE MODEL\n",
    "for epoch in range(1, 20):\n",
    "    train(train_loader,epoch, model, 0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set, Loss: 0.9163, Test error: 0.3833\n",
      "Accuracy : 0.6166666666666667\n",
      "Precision : 0.574468085106383\n",
      "Recall : 0.9\n",
      "F1 Score : 0.7012987012987013\n"
     ]
    }
   ],
   "source": [
    "test(test_loader,y_test,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_CLAM = {'gated':[True,False],'size_arg':['big','small'], 'dropout': [0,0.1,0.2,0.3,0.5], 'k_samples':[5,8,10,12], 'lr': [0.001, 0.01], 'weight_decay': [0.0005, 0.005]}\n",
    "\n",
    "hyperparam_tuning(train_loader, test_loader, y_test, hyp_CLAM,CLAM_SB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TransMIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nystrom-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransMIL(n_classes=2)\n",
    "for epoch in range(1, 10):\n",
    "    train(train_loader, epoch, model, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(test_loader, y_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DSMIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_classifier = dsmil.IClassifier(feature_extractor=nn.Identity(),feature_size=1024, output_class=1)\n",
    "b_classifier = dsmil.BClassifier(input_size=1024, output_class=1)\n",
    "model = dsmil.MILNet(i_classifier, b_classifier)\n",
    "for epoch in range(1, 20):\n",
    "    train(train_loader, epoch, model, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(test_loader, y_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepGraphConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dgc.DeepGraphConv_Surv(n_classes=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DeepGraphConv_Surv.forward() missing 2 required positional arguments: 'edge_index' and 'edge_latent'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     train(train_loader, epoch, model, \u001b[38;5;241m0.001\u001b[39m)\n",
      "File \u001b[0;32m~/EPFL/MA2/ML/ML4Science/src/utils.py:23\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_loader, epoch, model, lr, weight_decay, print_results)\u001b[0m\n\u001b[1;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# calculate loss and metrics\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m loss, _ \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcalculate_objective(data, bag_label)\n\u001b[1;32m     24\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     25\u001b[0m error, _ \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcalculate_classification_error(data, bag_label)\n",
      "File \u001b[0;32m~/EPFL/MA2/ML/ML4Science/src/MIL/DeepGraphConv.py:95\u001b[0m, in \u001b[0;36mDeepGraphConv_Surv.calculate_objective\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_objective\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y):\n\u001b[1;32m     94\u001b[0m     Y \u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m---> 95\u001b[0m     logits, Y_prob, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(X)\n\u001b[1;32m     96\u001b[0m     Y_prob \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(Y_prob, \u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1e-5\u001b[39m)\n\u001b[1;32m     97\u001b[0m     loss \u001b[38;5;241m=\u001b[39m neg_log_bernouilli(Y, Y_prob[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: DeepGraphConv_Surv.forward() missing 2 required positional arguments: 'edge_index' and 'edge_latent'"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 10):\n",
    "    train(train_loader, epoch, model, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACMIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ACMIL_GA(embed_dim =1024,hidden_size = 512, n_classes =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.2821, Train error: 0.0692\n",
      "Epoch: 2, Loss: 0.1757, Train error: 0.0385\n",
      "Epoch: 3, Loss: 0.0824, Train error: 0.0308\n",
      "Epoch: 4, Loss: 0.0459, Train error: 0.0154\n",
      "Epoch: 5, Loss: 0.0468, Train error: 0.0231\n",
      "Epoch: 6, Loss: 0.0183, Train error: 0.0077\n",
      "Epoch: 7, Loss: 0.1816, Train error: 0.0538\n",
      "Epoch: 8, Loss: 0.0650, Train error: 0.0308\n",
      "Epoch: 9, Loss: 0.1038, Train error: 0.0154\n",
      "Epoch: 10, Loss: 0.1078, Train error: 0.0308\n",
      "Epoch: 11, Loss: 0.1031, Train error: 0.0462\n",
      "Epoch: 12, Loss: 0.0628, Train error: 0.0154\n",
      "Epoch: 13, Loss: 0.0564, Train error: 0.0077\n",
      "Epoch: 14, Loss: 0.0782, Train error: 0.0154\n",
      "Epoch: 15, Loss: 0.1317, Train error: 0.0538\n",
      "Epoch: 16, Loss: 0.0897, Train error: 0.0154\n",
      "Epoch: 17, Loss: 0.1175, Train error: 0.0231\n",
      "Epoch: 18, Loss: 0.0912, Train error: 0.0154\n",
      "Epoch: 19, Loss: 0.0630, Train error: 0.0231\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 20):\n",
    "    train(train_loader, epoch, model, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set, Loss: 3.3487, Test error: 0.5000\n",
      "Accuracy : 0.5\n",
      "Precision : 0.5\n",
      "Recall : 1.0\n",
      "F1 Score : 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "test(test_loader, y_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AttriMIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AttriMIL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.5549, Train error: 0.0923\n",
      "Epoch: 2, Loss: 0.6030, Train error: 0.1077\n",
      "Epoch: 3, Loss: 0.1979, Train error: 0.0538\n",
      "Epoch: 4, Loss: 0.3287, Train error: 0.0538\n",
      "Epoch: 5, Loss: 0.2480, Train error: 0.0769\n",
      "Epoch: 6, Loss: 0.1365, Train error: 0.0615\n",
      "Epoch: 7, Loss: 0.2547, Train error: 0.0538\n",
      "Epoch: 8, Loss: 0.1195, Train error: 0.0385\n",
      "Epoch: 9, Loss: 0.1884, Train error: 0.0462\n",
      "Epoch: 10, Loss: 0.1243, Train error: 0.0308\n",
      "Epoch: 11, Loss: 0.1786, Train error: 0.0538\n",
      "Epoch: 12, Loss: 0.2912, Train error: 0.0462\n",
      "Epoch: 13, Loss: 0.1356, Train error: 0.0462\n",
      "Epoch: 14, Loss: 0.1503, Train error: 0.0538\n",
      "Epoch: 15, Loss: 0.0760, Train error: 0.0385\n",
      "Epoch: 16, Loss: 0.0954, Train error: 0.0154\n",
      "Epoch: 17, Loss: 0.3214, Train error: 0.0462\n",
      "Epoch: 18, Loss: 0.1812, Train error: 0.0308\n",
      "Epoch: 19, Loss: 0.1553, Train error: 0.0462\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 20):\n",
    "    train(train_loader, epoch, model, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set, Loss: 3.3487, Test error: 0.5000\n",
      "Accuracy : 0.5\n",
      "Precision : 0.5\n",
      "Recall : 1.0\n",
      "F1 Score : 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "test(test_loader, y_test, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
